{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImage(Path):\n",
    "    return cv2.imread(Path, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitImage(Image, data):\n",
    "    _img = [np.hsplit(row, data[0]) for row in np.vsplit(Image, data[1])]\n",
    "    return np.array(_img, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliceImage(Image):\n",
    "    return Image[:, :50].reshape(-1, (20*20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(Title, Image):\n",
    "    cv2.namedWindow(Title, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(Title, Image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN using DIGITS DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.64\n"
     ]
    }
   ],
   "source": [
    "mnist = readImage('../datasets/digits.png')\n",
    "splitted_img = splitImage(mnist, [100, 50])\n",
    "train_img = splitted_img[:, :50].reshape(-1, (20*20))\n",
    "test_img = splitted_img[:, 50:100].reshape(-1, (20*20))\n",
    "k = np.arange(10)\n",
    "train_labels =  np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_img, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "ret, result , neighbors, dist = knn.findNearest(test_img, 3)\n",
    "matches = np.equal(result, test_labels)\n",
    "\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "accuracy = (correct * 100.00) / result.size\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN USING FASHION DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.8888888889\n"
     ]
    }
   ],
   "source": [
    "mnist = readImage('../datasets/fashion.png')\n",
    "splitted_img = splitImage(mnist, [30, 30])\n",
    "train_img = splitted_img[:, :15].reshape(-1, (28*28))\n",
    "test_img = splitted_img[:, 15:30].reshape(-1, (28*28))\n",
    "k = np.arange(10)\n",
    "train_labels =  np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_img, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "ret, result , neighbors, dist = knn.findNearest(test_img, 3)\n",
    "matches = np.equal(result, test_labels)\n",
    "\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "accuracy = (correct * 100.00) / result.size\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM for DIGITS DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.44\n"
     ]
    }
   ],
   "source": [
    "mnist = readImage('../datasets/digits.png')\n",
    "splitted_img = splitImage(mnist, [100, 50])\n",
    "train_img = splitted_img[:, :50].reshape(-1, (20*20))\n",
    "test_img = splitted_img[:, 50:100].reshape(-1, (20*20))\n",
    "k = np.arange(10)\n",
    "train_labels =  np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "model = cv2.ml.SVM_create()\n",
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)\n",
    "\n",
    "#Train\n",
    "model.train(train_img, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "#USING TRAINED SVM\n",
    "result = model.predict(test_img)\n",
    "\n",
    "#Accuracy\n",
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size\n",
    "\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM for FASHION DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.6666666667\n"
     ]
    }
   ],
   "source": [
    "mnist = readImage('../datasets/fashion.png')\n",
    "splitted_img = splitImage(mnist, [30, 30])\n",
    "train_img = splitted_img[:, :15].reshape(-1, (28*28))\n",
    "test_img = splitted_img[:, 15:30].reshape(-1, (28*28))\n",
    "k = np.arange(10)\n",
    "train_labels =  np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "model = cv2.ml.SVM_create()\n",
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)\n",
    "\n",
    "#Train\n",
    "model.train(train_img, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "#USING TRAINED SVM\n",
    "result = model.predict(test_img)\n",
    "\n",
    "#Accuracy\n",
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEAN NORMALIZATION ~ KNN DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.24\n"
     ]
    }
   ],
   "source": [
    "mnist = readImage('../datasets/digits.png')\n",
    "splitted_img = splitImage(mnist, [100, 50])\n",
    "train_img = splitted_img[:, :50].reshape(-1, (20*20))\n",
    "test_img = splitted_img[:, 50:100].reshape(-1, (20*20))\n",
    "k = np.arange(10)\n",
    "train_labels =  np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "\n",
    "train_img -= np.mean(train_img, axis=0)\n",
    "test_img -= np.mean(train_img, axis=0)\n",
    "\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_img, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "ret, result , neighbors, dist = knn.findNearest(test_img, 3)\n",
    "matches = np.equal(result, test_labels)\n",
    "\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "accuracy = (correct * 100.00) / result.size\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEAN NORMALIZATION ~ KNN FASHION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.0\n"
     ]
    }
   ],
   "source": [
    "mnist = readImage('../datasets/fashion.png')\n",
    "splitted_img = splitImage(mnist, [30, 30])\n",
    "train_img = splitted_img[:, :15].reshape(-1, (28*28))\n",
    "test_img = splitted_img[:, 15:30].reshape(-1, (28*28))\n",
    "k = np.arange(10)\n",
    "train_labels =  np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "\n",
    "\n",
    "train_img -= np.mean(train_img, axis=0)\n",
    "test_img -= np.mean(train_img, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_img, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "ret, result , neighbors, dist = knn.findNearest(test_img, 3)\n",
    "matches = np.equal(result, test_labels)\n",
    "\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "accuracy = (correct * 100.00) / result.size\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEAN NORMALIZATION ~ SVM DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.8\n"
     ]
    }
   ],
   "source": [
    "mnist = readImage('../datasets/digits.png')\n",
    "splitted_img = splitImage(mnist, [100, 50])\n",
    "train_img = splitted_img[:, :50].reshape(-1, (20*20))\n",
    "test_img = splitted_img[:, 50:100].reshape(-1, (20*20))\n",
    "k = np.arange(10)\n",
    "train_labels =  np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "\n",
    "\n",
    "train_img -= np.mean(train_img, axis=0)\n",
    "test_img -= np.mean(train_img, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "model = cv2.ml.SVM_create()\n",
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)\n",
    "\n",
    "#Train\n",
    "model.train(train_img, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "#USING TRAINED SVM\n",
    "result = model.predict(test_img)\n",
    "\n",
    "#Accuracy\n",
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size\n",
    "\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEAN NORMALIZATION ~ SVM FASHION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.4444444444\n"
     ]
    }
   ],
   "source": [
    "mnist = readImage('../datasets/fashion.png')\n",
    "splitted_img = splitImage(mnist, [30, 30])\n",
    "train_img = splitted_img[:, :15].reshape(-1, (28*28))\n",
    "test_img = splitted_img[:, 15:30].reshape(-1, (28*28))\n",
    "k = np.arange(10)\n",
    "train_labels =  np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "\n",
    "\n",
    "train_img -= np.mean(train_img, axis=0)\n",
    "test_img -= np.mean(train_img, axis=0)\n",
    "\n",
    "\n",
    "model = cv2.ml.SVM_create()\n",
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)\n",
    "\n",
    "#Train\n",
    "model.train(train_img, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "#USING TRAINED SVM\n",
    "result = model.predict(test_img)\n",
    "\n",
    "#Accuracy\n",
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = readImage('../datasets/digits.png')\n",
    "splitted_img = splitImage(mnist, [100, 50])\n",
    "train_img = splitted_img[:, :50].reshape(-1, (20*20))\n",
    "test_img = splitted_img[:, 50:100].reshape(-1, (20*20))\n",
    "pca = PCA(n_components=train_img.shape[1])\n",
    "pca.fit(train_img)\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA ~ KNN ~ DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.24\n"
     ]
    }
   ],
   "source": [
    "mnist = readImage('../datasets/digits.png')\n",
    "splitted_img = splitImage(mnist, [100, 50])\n",
    "train_img = splitted_img[:, :50].reshape(-1, (20*20))\n",
    "test_img = splitted_img[:, 50:100].reshape(-1, (20*20))\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "pca.fit(train_img)\n",
    "\n",
    "train_img = pca.transform(train_img)\n",
    "test_img = pca.transform(test_img)\n",
    "\n",
    "k = np.arange(10)\n",
    "train_labels =  np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_img, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "ret, result , neighbors, dist = knn.findNearest(test_img, 3)\n",
    "matches = np.equal(result, test_labels)\n",
    "\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "accuracy = (correct * 100.00) / result.size\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA ~ KNN ~ FASHION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.2222222222\n"
     ]
    }
   ],
   "source": [
    "mnist = readImage('../datasets/fashion.png')\n",
    "splitted_img = splitImage(mnist, [30, 30])\n",
    "train_img = splitted_img[:, :15].reshape(-1, (28*28))\n",
    "test_img = splitted_img[:, 15:30].reshape(-1, (28*28))\n",
    "\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "pca.fit(train_img)\n",
    "\n",
    "train_img = pca.transform(train_img)\n",
    "test_img = pca.transform(test_img)\n",
    "\n",
    "\n",
    "k = np.arange(10)\n",
    "train_labels =  np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_img, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "ret, result , neighbors, dist = knn.findNearest(test_img, 3)\n",
    "matches = np.equal(result, test_labels)\n",
    "\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "accuracy = (correct * 100.00) / result.size\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA ~ SVM ~ DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.48\n"
     ]
    }
   ],
   "source": [
    "mnist = readImage('../datasets/digits.png')\n",
    "splitted_img = splitImage(mnist, [100, 50])\n",
    "train_img = splitted_img[:, :50].reshape(-1, (20*20))\n",
    "test_img = splitted_img[:, 50:100].reshape(-1, (20*20))\n",
    "\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "pca.fit(train_img)\n",
    "\n",
    "train_img = pca.transform(train_img)\n",
    "test_img = pca.transform(test_img)\n",
    "\n",
    "k = np.arange(10)\n",
    "train_labels =  np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "model = cv2.ml.SVM_create()\n",
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)\n",
    "\n",
    "#Train\n",
    "model.train(train_img, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "#USING TRAINED SVM\n",
    "result = model.predict(test_img)\n",
    "\n",
    "#Accuracy\n",
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size\n",
    "\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA ~ SVM ~ FASHION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.6666666667\n"
     ]
    }
   ],
   "source": [
    "mnist = readImage('../datasets/fashion.png')\n",
    "splitted_img = splitImage(mnist, [30, 30])\n",
    "train_img = splitted_img[:, :15].reshape(-1, (28*28))\n",
    "test_img = splitted_img[:, 15:30].reshape(-1, (28*28))\n",
    "\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "pca.fit(train_img)\n",
    "\n",
    "train_img = pca.transform(train_img)\n",
    "test_img = pca.transform(test_img)\n",
    "\n",
    "\n",
    "k = np.arange(10)\n",
    "train_labels =  np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()\n",
    "\n",
    "model = cv2.ml.SVM_create()\n",
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)\n",
    "\n",
    "#Train\n",
    "model.train(train_img, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "#USING TRAINED SVM\n",
    "result = model.predict(test_img)\n",
    "\n",
    "#Accuracy\n",
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
